"""
Pipeline CV complet: PDF ‚Üí Images ‚Üí Pr√©diction
"""
import torch
import sys
import os
import numpy as np
from pathlib import Path


sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from preprocessing.pdf_to_images import pdf_to_images
from cv_module.hybrid_model import HybridDocumentClassifier
from cv_module.gabarit_detector import GabaritDetector
from cv_module.dataset_utils import get_transforms


class CVPipeline:
    def __init__(self, model_path="models/cv/best_model.pth", device='cpu'):
        """
        Pipeline complet de classification visuelle
        
        Args:
            model_path: Chemin vers le mod√®le entra√Æn√©
            device: 'cuda' ou 'cpu'
        """
        self.device = torch.device(device)
        
        # Classes (IMPORTANT: m√™me ordre que l'entra√Ænement)
        self.classes = [
            'document_employeur',
            'facture_eau',
            'facture_electricite',
            'identite',
            'releve_bancaire'
        ]
        
        # Charger mod√®le
        print(f"üìÇ Chargement du mod√®le depuis {model_path}...")
        self.model = HybridDocumentClassifier(
            num_classes=len(self.classes),
            num_gabarit_features=9,
            pretrained=False
        )
        
        checkpoint = torch.load(model_path, map_location=self.device)
        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.model.to(self.device)
        self.model.eval()
        
        # Autres modules
        self.gabarit_detector = GabaritDetector()
        self.transform = get_transforms(train=False)
        
        print(f"‚úÖ Pipeline CV initialis√© (device: {self.device})")
        print(f"   Classes: {self.classes}")
    
    def extract_gabarit_features(self, image_tensor):
        """
        Extrait features de gabarits d'une image
        
        Args:
            image_tensor: Tensor (3, 224, 224) normalis√©
            
        Returns:
            Tensor (9,) avec features
        """
        # D√©normaliser
        img_np = image_tensor.cpu().numpy().transpose(1, 2, 0)
        mean = np.array([0.485, 0.456, 0.406])
        std = np.array([0.229, 0.224, 0.225])
        img_np = img_np * std + mean
        img_np = (img_np * 255).astype('uint8')
        
        # Extraire features
        features_dict = self.gabarit_detector.extract_features(img_np)
        
        # Convertir en liste ordonn√©e
        features_list = [
            features_dict['ratio_carte'],
            features_dict['ratio_a4'],
            features_dict['has_face'],
            features_dict['table_score'],
            features_dict['blue_dominant'],
            features_dict['green_dominant'],
            features_dict['text_density'],
            features_dict['signature_zone'],
            features_dict['numbers_density']
        ]
        
        return torch.FloatTensor(features_list)
    
    def predict_image(self, image_path):
        """
        Pr√©dit la classe d'une image
        
        Returns:
            dict: {
                'category': cat√©gorie pr√©dite,
                'confidence': niveau de confiance,
                'all_scores': scores pour toutes les classes,
                'gabarit_scores': scores gabarits
            }
        """
        # Charger et transformer image
        from PIL import Image
        image = Image.open(image_path).convert('RGB')
        image_tensor = self.transform(image).unsqueeze(0).to(self.device)
        
        # Features gabarits
        gabarit_features = self.extract_gabarit_features(self.transform(image))
        gabarit_features = gabarit_features.unsqueeze(0).to(self.device)
        
        # Pr√©diction
        with torch.no_grad():
            outputs = self.model(image_tensor, gabarit_features)
            probs = torch.softmax(outputs, dim=1)[0]
        
        # R√©sultats
        predicted_idx = torch.argmax(probs).item()
        confidence = probs[predicted_idx].item()
        category = self.classes[predicted_idx]
        
        # Tous les scores CNN
        all_scores = {
            self.classes[i]: probs[i].item() 
            for i in range(len(self.classes))
        }
        
        # Scores gabarits
        gabarit_scores = self.gabarit_detector.compute_gabarit_scores(
            self.gabarit_detector.extract_features(image_path)
        )
        
        return {
            'category': category,
            'confidence': confidence,
            'all_scores': all_scores,
            'gabarit_scores': gabarit_scores
        }
    
    def process_pdf(self, pdf_path, output_dir="data/images"):
        """
        Traite un PDF complet
        
        Returns:
            dict: R√©sultat pour la premi√®re page (ou agr√©g√©)
        """
        pdf_path = Path(pdf_path)
        output_dir = Path(output_dir)
        print(f"\n{'='*60}")
        print(f"üñº  Traitement CV: {pdf_path}")
        print(f"{'='*60}")
        
        # Convertir PDF en images
        print("üîÑ Conversion PDF ‚Üí Images...")
        image_paths = pdf_to_images(pdf_path, output_dir)
        
        if not image_paths:
            return {
                'category': 'UNKNOWN',
                'confidence': 0.0,
                'all_scores': {},
                'gabarit_scores': {}
            }
        
        print(f"‚úÖ {len(image_paths)} page(s) convertie(s)")
        
        # Pr√©dire sur la premi√®re page
        print("ü§ñ Classification en cours...")
        result = self.predict_image(image_paths[0])
        
        # Affichage
        print(f"\nüìä R√©sultats CV:")
        print(f"  Cat√©gorie: {result['category']}")
        print(f"  Confiance: {result['confidence']:.2%}")
        print(f"\n  Scores CNN:")
        for cat, score in sorted(result['all_scores'].items(), 
                                 key=lambda x: x[1], reverse=True):
            print(f"    {cat}: {score:.2%}")
        print(f"\n  Scores Gabarits:")
        for cat, score in sorted(result['gabarit_scores'].items(), 
                                 key=lambda x: x[1], reverse=True):
            print(f"    {cat}: {score:.2%}")
        
        return result


# Test
if __name__ == "__main__":
    # Initialiser le pipeline
    pipeline = CVPipeline()
    
    # Tester sur un PDF
    test_pdf = r".\SRM.pdf"
    
    if os.path.exists(test_pdf):
        result = pipeline.process_pdf(test_pdf)
    else:
        print(f"‚ùå Fichier de test non trouv√©: {test_pdf}")
        print("Modifie le chemin dans le script pour tester.")
    
    print("\n‚úÖ Pipeline CV pr√™t √† l'emploi!")